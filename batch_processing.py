import logging
import asyncio
from config import bitrix  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π BitrixAsync –∏–∑ config
from db_management import get_unprocessed_webhooks, mark_webhook_as_processed, save_task_to_db, \
    get_task_id_by_deal_id, delete_task_from_db
from process_functions import process_contact_update, process_deal_add, process_deal_update

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.DEBUG,  # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logging.getLogger('fast_bitrix24').addHandler(logging.StreamHandler())


# ========== –ü–∞–∫–µ—Ç–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ Bitrix ==========

async def fetch_batch_entity_info(entity_ids, entity_type):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—É—â–Ω–æ—Å—Ç—è—Ö (—Å–¥–µ–ª–∫–∞—Ö –∏–ª–∏ –∫–æ–Ω—Ç–∞–∫—Ç–∞—Ö) –∏–∑ Bitrix –≤ –ø–∞–∫–µ—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ.

    :param entity_ids: –°–ø–∏—Å–æ–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å—É—â–Ω–æ—Å—Ç–µ–π.
    :param entity_type: –¢–∏–ø —Å—É—â–Ω–æ—Å—Ç–∏ - 'deal' –∏–ª–∏ 'contact'.
    :return: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—É—â–Ω–æ—Å—Ç—è—Ö.
    """
    if not entity_ids:
        logging.debug("–°–ø–∏—Å–æ–∫ entity_ids –ø—É—Å—Ç. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫.")
        return []

    all_entity_info = []
    batch_size = 50  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä batch-–∑–∞–ø—Ä–æ—Å–∞ –≤ Bitrix24
    total_entities = len(entity_ids)
    logging.debug(f"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {total_entities} —Å—É—â–Ω–æ—Å—Ç–µ–π —Ç–∏–ø–∞ '{entity_type}' —Å batch_size={batch_size}.")

    for i in range(0, total_entities, batch_size):
        chunk_ids = entity_ids[i:i + batch_size]
        operations = {
            f"{entity_type}_{idx}": f"crm.{entity_type}.get?ID={entity_id}"
            for idx, entity_id in enumerate(chunk_ids)
        }
        logging.debug(f"–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω batch-—á–∞–Ω–∫ —Å {len(chunk_ids)} —Å—É—â–Ω–æ—Å—Ç—è–º–∏: {chunk_ids}")

        try:
            response = await bitrix.call_batch({
                'halt': 0,
                'cmd': operations
            })
            logging.debug(f"–û—Ç–≤–µ—Ç –æ—Ç Bitrix –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞: {response}")

            if isinstance(response, dict):
                all_entity_info.extend(response.values())
                logging.info(f"–£—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω–æ {len(response.values())} –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Ç–∏–ø–∞ '{entity_type}' –≤ —Ç–µ–∫—É—â–µ–º —á–∞–Ω–∫–µ.")
            else:
                logging.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞: {response}")

        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ batch-–∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —Å—É—â–Ω–æ—Å—Ç–µ–π {chunk_ids}: {e}")

    logging.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ {len(all_entity_info)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Ç–∏–ø–∞ '{entity_type}'.")
    return all_entity_info


# ========== –ü–∞–∫–µ—Ç–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ Bitrix ==========

# –§—É–Ω–∫—Ü–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π –Ω–∞ —á–∞–Ω–∫–∏ (–±–µ–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è)
def chunk_operations(operations, batch_size):
    operations_list = list(operations.items())
    for i in range(0, len(operations_list), batch_size):
        yield dict(operations_list[i:i + batch_size])


async def send_batch_chunk(batch_chunk, batch_size=50, max_retries=5):
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç batch-–∑–∞–ø—Ä–æ—Å –≤ Bitrix –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è.
    """
    retry_count = 0
    while retry_count < max_retries:
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º batch-–∫–æ–º–∞–Ω–¥—É
            batch_cmd = {'halt': 0, 'cmd': batch_chunk}
            logging.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ batch-–∑–∞–ø—Ä–æ—Å–∞: {list(batch_chunk.keys())}")

            # –í—ã–ø–æ–ª–Ω—è–µ–º batch-–∑–∞–ø—Ä–æ—Å
            response = await bitrix.call_batch(batch_cmd)

            # üõë –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—à–∏–±–∫–∏ –∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º "Not found"
            if 'result_error' in response:
                for operation, error in response['result_error'].items():
                    if isinstance(error, dict) and error.get('error_description') == 'Not found':
                        logging.info(f"‚úÖ Bitrix –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª —É–¥–∞–ª–µ–Ω–∏–µ —Å–¥–µ–ª–∫–∏ {operation}. –û—à–∏–±–∫–∞ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è.")
                        response['result_error'].pop(operation)  # –£–±–∏—Ä–∞–µ–º –æ—à–∏–±–∫—É, —á—Ç–æ–±—ã –Ω–µ –≤—ã–∑—ã–≤–∞—Ç—å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
            if 'error' in response:
                error_type = response.get('error')
                if error_type == 'ERROR_BATCH_LENGTH_EXCEEDED' and batch_size > 1:
                    logging.warning("–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç batch-–∑–∞–ø—Ä–æ—Å–∞. –†–∞–∑–¥–µ–ª—è–µ–º.")
                    results = {}
                    for smaller_chunk in chunk_operations(batch_chunk, batch_size // 2):
                        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –º–µ–ª–∫–∏–µ —á–∞–Ω–∫–∏
                        chunk_result = await send_batch_chunk(smaller_chunk, batch_size // 2, max_retries)
                        results.update(chunk_result)  # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    logging.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ batch-–∑–∞–ø—Ä–æ—Å–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç: {response}")
                    return results
                else:
                    logging.error(f"–û—à–∏–±–∫–∞ –≤ batch-–∑–∞–ø—Ä–æ—Å–µ: {response['error']}")
                    return {}

            # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç
            logging.info("Batch —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω.")
            logging.debug(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã batch-–∑–∞–ø—Ä–æ—Å–∞: {response}")

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–≤–µ—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º TASK_ID
            process_batch_response(response)

            return response  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        except Exception as e:
            retry_count += 1
            logging.error(f"–û—à–∏–±–∫–∞ –≤ batch-–∑–∞–ø—Ä–æ—Å–µ. –ü–æ–ø—ã—Ç–∫–∞ {retry_count}: {e}")
            await asyncio.sleep(2)

    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫ –∑–∞–ø—Ä–æ—Å –Ω–µ —É–¥–∞–ª—Å—è
    logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —á–∞–Ω–∫ –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {list(batch_chunk.keys())}")
    return {}


# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ batch-–∑–∞–ø—Ä–æ—Å
def process_batch_response(response):
    for operation, result in response.items():
        if operation.startswith("almaty_task_"):
            deal_id = int(operation.split("_")[2])  # –ò–∑–≤–ª–µ–∫–∞–µ–º deal_id –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏
            task_data = result.get("task", {})
            task_id = task_data.get("id")
            if task_id:
                save_task_to_db(deal_id, task_id)


async def batch_send_to_bitrix():
    """
    –ü–æ–ª—É—á–∞–µ—Ç –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –≤–µ–±—Ö—É–∫–∏, –∏–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Bitrix –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏—Ö –Ω–∞ –¥–∞–ª—å–Ω–µ–π—à—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É.
    """
    logging.info("–ó–∞–ø—É—Å–∫ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
    webhooks = get_unprocessed_webhooks()
    if not webhooks:
        logging.info("–ù–µ—Ç –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –≤–µ–±—Ö—É–∫–æ–≤.")
        return

    logging.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(webhooks)} –≤–µ–±—Ö—É–∫–æ–≤.")
    await asyncio.sleep(2)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏

    deal_ids = set()
    contact_ids = set()
    deal_update_ids = set()
    operations = {}
    unregistered_deals = []

    # –°–±–æ—Ä –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å—É—â–Ω–æ—Å—Ç–µ–π
    for webhook in webhooks:
        entity_id = webhook['entity_id']
        event_type = webhook['event_type']
        if event_type == "ONCRMDEALADD":
            deal_ids.add(entity_id)
        elif event_type == "ONCRMCONTACTUPDATE":
            contact_ids.add(entity_id)
        elif event_type == "ONCRMDEALUPDATE":
            deal_update_ids.add(entity_id)

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–¥–µ–ª–∫–∞—Ö
    if deal_ids:
        deal_info_list = await fetch_batch_entity_info(list(deal_ids), "deal")
        for deal_info in deal_info_list:
            try:
                await process_deal_add(deal_info, operations, unregistered_deals)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–¥–µ–ª–∫–∏ {deal_info['ID']}: {e}")

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–Ω—Ç–∞–∫—Ç–∞—Ö
    if contact_ids:
        contact_info_list = await fetch_batch_entity_info(list(contact_ids), "contact")
        for contact_info in contact_info_list:
            try:
                await process_contact_update(contact_info)
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–Ω—Ç–∞–∫—Ç–∞ {contact_info['ID']}: {e}")

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö —Å–¥–µ–ª–∫–∞—Ö
    if deal_update_ids:
        deal_update_info_list = await fetch_batch_entity_info(list(deal_update_ids), "deal")
        for deal_info in deal_update_info_list:
            try:
                await process_deal_update(deal_info)  # –í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π —Å–¥–µ–ª–æ–∫
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–π —Å–¥–µ–ª–∫–∏ {deal_info['ID']}: {e}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–∫-–Ω–æ–º–µ—Ä–æ–≤
    await handle_unregistered_deals(unregistered_deals, operations)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ batch-–∑–∞–ø—Ä–æ—Å–æ–≤
    if operations:
        for batch_chunk in chunk_operations(operations, batch_size=50):
            await send_batch_chunk(batch_chunk)
            await asyncio.sleep(1)
    else:
        logging.warning("–ù–µ—Ç –æ–ø–µ—Ä–∞—Ü–∏–π –¥–ª—è batch-–∑–∞–ø—Ä–æ—Å–∞.")

    # –û—Ç–º–µ—á–∞–µ–º –≤–µ–±—Ö—É–∫–∏ –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ
    for webhook in webhooks:
        try:
            mark_webhook_as_processed(webhook['id'])
            logging.info(f"–í–µ–±—Ö—É–∫ {webhook['id']} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω.")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–µ–±—Ö—É–∫–∞ {webhook['id']}: {e}")


async def handle_unregistered_deals(unregistered_deals, operations):
    if not unregistered_deals:
        logging.info("–ù–µ—Ç —Å–¥–µ–ª–æ–∫ –±–µ–∑ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–∫-–Ω–æ–º–µ—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
        return

    logging.info(f"–ù–∞—á–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(unregistered_deals)} —Å–¥–µ–ª–æ–∫ –±–µ–∑ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–µ–∫-–Ω–æ–º–µ—Ä–æ–≤.")

    # –®–∞–≥ 1: –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    search_operations = {}
    for idx, deal in enumerate(unregistered_deals):
        track_number = deal.get('track_number')
        if not track_number:
            logging.warning(f"–ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å–¥–µ–ª–∫–∞ ID: {deal['ID']} –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Ç—Ä–µ–∫-–Ω–æ–º–µ—Ä–∞.")
            continue

        search_operations[f"search_{idx}"] = (
            f"crm.deal.list?"
            f"filter[UF_CRM_1723542556619]={track_number}&"
            f"filter[!ID]={deal['ID']}&"
            f"select[]=ID&"
            f"select[]=STAGE_ID"
        )
        logging.debug(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –æ–ø–µ—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞: search_{idx} –¥–ª—è —Ç—Ä–µ–∫-–Ω–æ–º–µ—Ä–∞ {track_number}")

    logging.info(f"–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ {len(search_operations)} –æ–ø–µ—Ä–∞—Ü–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.")

    # –®–∞–≥ 2: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å—ã —á–∞–Ω–∫–∞–º–∏
    duplicate_results = {}
    for batch_chunk in chunk_operations(search_operations, batch_size=50):
        logging.debug(f"–û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–π batch-—á–∞–Ω–∫: {batch_chunk}")
        chunk_result = await send_batch_chunk(batch_chunk)
        logging.debug(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã batch-—á–∞–Ω–∫–∞: {chunk_result}")
        if chunk_result:
            duplicate_results.update(chunk_result)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ—Ç–µ—Ä—è–ª–∏—Å—å –ª–∏ –¥–∞–Ω–Ω—ã–µ
    logging.debug(f"–ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicate_results}")

    # –®–∞–≥ 3: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
    duplicate_ids = set()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º set –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π

    for idx, deal in enumerate(unregistered_deals):
        deal_stage_id = deal.get('STAGE_ID')
        deal_id = deal.get('ID')
        logging.debug(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —Å–¥–µ–ª–∫–∞ ID={deal_id}, STAGE_ID={deal_stage_id}")

        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –ø–æ–∏—Å–∫–∞
        for key, result_list in duplicate_results.items():
            if not isinstance(result_list, list):
                logging.warning(f"–û–∂–∏–¥–∞–ª—Å—è —Å–ø–∏—Å–æ–∫, –Ω–æ –ø–æ–ª—É—á–µ–Ω–æ {type(result_list)} –¥–ª—è –∫–ª—é—á–∞ {key}. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                continue

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
            for duplicate in result_list:
                duplicate_stage_id = duplicate.get('STAGE_ID')
                duplicate_id = duplicate.get('ID')

                if duplicate_id != deal_id and duplicate_stage_id != deal_stage_id:
                    # logging.debug(f"–î–æ–±–∞–≤–ª–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: ID={duplicate_id}, STAGE_ID={duplicate_stage_id}")
                    duplicate_ids.add(duplicate_id)
                # else:
                #     logging.debug(f"–ò—Å–∫–ª—é—á—ë–Ω –∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: ID={duplicate_id}, STAGE_ID={duplicate_stage_id}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã
    if not duplicate_ids:
        logging.info("–î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
        return

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π
    duplicate_ids = list(duplicate_ids)

    logging.info(f"–ù–∞–π–¥–µ–Ω–æ {len(duplicate_ids)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤. –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ.")

    # –®–∞–≥ 4: –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ
    for idx, deal_id in enumerate(duplicate_ids):
        operations[f"delete_{idx}"] = f"crm.deal.delete?id={deal_id}"
        logging.debug(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –æ–ø–µ—Ä–∞—Ü–∏—è —É–¥–∞–ª–µ–Ω–∏—è: delete_{idx} –¥–ª—è ID={deal_id}")

        # –ü–æ–ª—É—á–∞–µ–º TASK_ID –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å–¥–µ–ª–∫–∏
        task_id = get_task_id_by_deal_id(deal_id)
        if task_id:
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–µ—Ä–∞—Ü–∏—é –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ –∑–∞–¥–∞—á–∏
            operations[f"delete_task_{task_id}"] = f"tasks.task.delete?taskId={task_id}"
            logging.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –æ–ø–µ—Ä–∞—Ü–∏—è —É–¥–∞–ª–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ —Å ID {task_id} –¥–ª—è —Å–¥–µ–ª–∫–∏ {deal_id}.")

            # –£–¥–∞–ª—è–µ–º –∑–∞–ø–∏—Å—å –æ –∑–∞–¥–∞—á–µ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            delete_task_from_db(deal_id)
            logging.info(f"–ó–∞–ø–∏—Å—å –æ –∑–∞–¥–∞—á–µ —Å TASK_ID={task_id} –¥–ª—è —Å–¥–µ–ª–∫–∏ {deal_id} —É–¥–∞–ª–µ–Ω–∞ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.")
    logging.info(f"–û–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω—ã. –í—Å–µ–≥–æ –æ–ø–µ—Ä–∞—Ü–∏–π: {len(operations)}")
